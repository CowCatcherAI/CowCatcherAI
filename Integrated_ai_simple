from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import warnings
import os

# Suppress HuggingFace warnings
warnings.filterwarnings("ignore", category=UserWarning)
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

class ImprovedYOLOMoondreamAgent:
    def __init__(self, yolo_model_path="yolov11.pt"):
        print("üîÑ Loading models...")
        
        # Load YOLO model
        print("üì¶ Loading YOLO model...")
        self.yolo_model = YOLO(yolo_model_path)
        
        # Load Moondream model with error handling
        print("üåô Loading Moondream model...")
        try:
            self.moondream_model_id = "vikhyatk/moondream2"
            self.moondream_model = AutoModelForCausalLM.from_pretrained(
                self.moondream_model_id, 
                trust_remote_code=True,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None
            )
            self.moondream_tokenizer = AutoTokenizer.from_pretrained(self.moondream_model_id)
            print("‚úÖ Models loaded successfully!")
            
            # Check GPU availability
            if torch.cuda.is_available():
                print(f"üöÄ CUDA available: {torch.cuda.get_device_name()}")
            else:
                print("üíª Running on CPU (slower)")
                
        except Exception as e:
            print(f"‚ùå Error loading Moondream: {e}")
            self.moondream_model = None
            self.moondream_tokenizer = None
    
    def describe_with_moondream(self, image, question="Briefly describe what you see in this image."):
        """Improved Moondream description with error handling"""
        if self.moondream_model is None:
            return "Moondream model not available"
        
        try:
            # Resize image if too large (for speed)
            if image.size[0] > 512 or image.size[1] > 512:
                image.thumbnail((512, 512), Image.Resampling.LANCZOS)
            
            # Encode and describe
            enc_image = self.moondream_model.encode_image(image)
            response = self.moondream_model.answer_question(
                enc_image, 
                question, 
                self.moondream_tokenizer
            )
            return response.strip()
            
        except Exception as e:
            return f"Description error: {str(e)[:50]}..."
    
    def analyze_single_image(self, image_path, conf_threshold=0.4, max_detections=5):
        """
        Analyze a single image with improved output
        """
        if not os.path.exists(image_path):
            print(f"‚ùå File not found: {image_path}")
            return []
        
        print(f"üîç Analyzing: {image_path}")
        
        # Load image
        try:
            image = cv2.imread(image_path)
            if image is None:
                print("‚ùå Could not load image")
                return []
                
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(image_rgb)
            print(f"üì∏ Image loaded: {pil_image.size}")
            
        except Exception as e:
            print(f"‚ùå Error loading image: {e}")
            return []
        
        # Run YOLO prediction
        print("üéØ Running YOLO detection...")
        results = self.yolo_model.predict(
            source=image_path, 
            conf=conf_threshold, 
            verbose=False,
            save=False
        )
        
        descriptions = []
        detection_count = 0
        
        for r in results:
            boxes = r.boxes
            if boxes is not None:
                print(f"üîç Found {len(boxes)} detections")
                
                for i, box in enumerate(boxes):
                    if detection_count >= max_detections:
                        print(f"‚ö†Ô∏è  Maximum of {max_detections} detections analyzed")
                        break
                    
                    # Get bounding box info
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                    confidence = float(box.conf[0].cpu().numpy())
                    class_id = int(box.cls[0].cpu().numpy())
                    class_name = r.names[class_id]
                    
                    print(f"\nüìç Detection {detection_count + 1}:")
                    print(f"   Class: {class_name}")
                    print(f"   Confidence: {confidence:.2%}")
                    print(f"   Location: ({x1}, {y1}) ‚Üí ({x2}, {y2})")
                    
                    # Crop and validate
                    try:
                        cropped_image = pil_image.crop((x1, y1, x2, y2))
                        if cropped_image.size[0] < 10 or cropped_image.size[1] < 10:
                            print("   ‚ö†Ô∏è  Too small to analyze")
                            continue
                            
                        # Describe with Moondream
                        print("   üåô Moondream analysis...")
                        question = (
                            "Does the cow in this bounding box appear to be calving (giving birth), "
                            "for example with calf legs, head, or body parts visibly emerging "
                            "from under the cow‚Äôs tail?"
                        )
                        description = self.describe_with_moondream(cropped_image, question)
                        
                        detection_info = {
                            'class': class_name,
                            'confidence': confidence,
                            'bbox': (x1, y1, x2, y2),
                            'description': description,
                            'size': cropped_image.size
                        }
                        
                        descriptions.append(detection_info)
                        print(f"   üí¨ Description: {description}")
                        detection_count += 1
                        
                    except Exception as e:
                        print(f"   ‚ùå Error analyzing detection: {e}")
                        continue
                
                print(f"\n‚úÖ Analysis complete: {len(descriptions)} descriptions generated")
        
        return descriptions
    
    def create_annotated_image(self, image_path, descriptions, output_path="annotated_output.jpg"):
        """
        Create an annotated image with descriptions
        """
        image = cv2.imread(image_path)
        
        for i, det in enumerate(descriptions):
            x1, y1, x2, y2 = det['bbox']
            
            # Draw bounding box
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # Add text
            label = f"{det['class']}: {det['description'][:30]}..."
            cv2.putText(
                image, 
                label, 
                (x1, max(y1-10, 10)), 
                cv2.FONT_HERSHEY_SIMPLEX, 
                0.6, 
                (0, 255, 0), 
                2
            )
            
            # Add detection number
            cv2.putText(
                image, 
                str(i+1), 
                (x1+5, y1+20), 
                cv2.FONT_HERSHEY_SIMPLEX, 
                0.8, 
                (255, 255, 0), 
                2
            )
        
        cv2.imwrite(output_path, image)
        print(f"üíæ Annotated image saved: {output_path}")
        return output_path

# Test function
def test_agent():
    """Test the agent with an example"""
    print("üß™ Testing YOLO + Moondream Agent")
    print("=" * 50)
    
    # Initialize agent
    agent = ImprovedYOLOMoondreamAgent("yolo11m.pt")
    
    # Test with example image (replace with your own file)
    image_path = "example2.png"
    
    if os.path.exists(image_path):
        descriptions = agent.analyze_single_image(
            image_path, 
            conf_threshold=0.3, 
            max_detections=3
        )
        
        if descriptions:
            # Create annotated image
            agent.create_annotated_image(image_path, descriptions)
            
            # Print summary
            print("\nüìã SUMMARY:")
            print("=" * 50)
            for i, det in enumerate(descriptions, 1):
                print(f"{i}. {det['class']} ({det['confidence']:.1%})")
                print(f"   ‚Üí {det['description']}")
                print()
        else:
            print("‚ùå No descriptions generated")
    else:
        print(f"‚ùå Test file '{image_path}' not found")
        print("üí° Place an image named 'example.jpg' in this folder")

if __name__ == "__main__":
    test_agent()
